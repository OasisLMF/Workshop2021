{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Hazard Data\n",
    "\n",
    "Generate hazard module from source data\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard python libraries\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "# non-standard python libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "# constants\n",
    "\n",
    "#import geopy.distance\n",
    "#km_nm_factor = 1.852\n",
    "#earth_radius = 6373.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download event data from hurdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from URL and write to file\n",
    "raw_fn = 'source_data/raw_hurdat_data.txt'\n",
    "url = 'https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2020-052921.txt'\n",
    "data = requests.get(url)\n",
    "with open(raw_fn,'w') as fw:\n",
    "    fw.write(data.text)\n",
    "    \n",
    "# create an empty list to temoporarily store downloaded data\n",
    "data=[]\n",
    "\n",
    "# loop through downloaded data and parse by row\n",
    "with open(raw_fn,'r') as fr:\n",
    "    for row in fr:\n",
    "        if row[0:2]=='AL':\n",
    "            event_id=row[0:8]\n",
    "            event_name=row[19:28]\n",
    "            records=row[34:36]\n",
    "        else:\n",
    "            date=row[0:8]\n",
    "            time=row[10:14]\n",
    "            record_id=row[16]\n",
    "            system_status=row[19:21]\n",
    "            latitude=row[23:27]\n",
    "            lat_hem=row[27]\n",
    "            longitude=row[30:35]\n",
    "            lon_hem=row[35]\n",
    "            max_windspeed=row[39:41]\n",
    "            min_pressure=row[43:47]\n",
    "            radii_34kt_ne=row[49:53]\n",
    "            radii_34kt_se=row[55:59]\n",
    "            radii_34kt_sw=row[61:65]\n",
    "            radii_34kt_nw=row[67:71]\n",
    "            radii_50kt_ne=row[73:77]\n",
    "            radii_50kt_se=row[79:83]\n",
    "            radii_50kt_sw=row[85:89]\n",
    "            radii_50kt_nw=row[91:95]\n",
    "            radii_64kt_ne=row[97:101]\n",
    "            radii_64kt_se=row[103:107]\n",
    "            radii_64kt_sw=row[109:113]\n",
    "            radii_64kt_nw=row[115:119]\n",
    "            \n",
    "            row_data = [\n",
    "                event_id,\n",
    "                event_name,\n",
    "                records,\n",
    "                date,\n",
    "                time,\n",
    "                record_id,\n",
    "                system_status,\n",
    "                latitude,\n",
    "                lat_hem,\n",
    "                longitude,\n",
    "                lon_hem,\n",
    "                max_windspeed,\n",
    "                min_pressure,\n",
    "                radii_34kt_ne,\n",
    "                radii_34kt_se,\n",
    "                radii_34kt_sw,\n",
    "                radii_34kt_nw,\n",
    "                radii_50kt_ne,\n",
    "                radii_50kt_se,\n",
    "                radii_50kt_sw,\n",
    "                radii_50kt_nw,\n",
    "                radii_64kt_ne,\n",
    "                radii_64kt_se,\n",
    "                radii_64kt_sw,\n",
    "                radii_64kt_nw\n",
    "            ]\n",
    "            data.append(row_data)\n",
    "    \n",
    "# create a pandas dataframe with the list data\n",
    "cols = ['id','name','records','date','time','record_id','system_status','latitude',\n",
    "        'lat_hem','longitude','lon_hem','max_windspeed','min_pressure',\n",
    "        'radii_34kt_ne','radii_34kt_se','radii_34kt_sw','radii_34kt_nw',\n",
    "        'radii_50kt_ne','radii_50kt_se','radii_50kt_sw','radii_50kt_nw',\n",
    "        'radii_64kt_ne','radii_64kt_se','radii_64kt_sw','radii_64kt_nw']\n",
    "\n",
    "\n",
    "\n",
    "df_data=pd.DataFrame(data=data,columns=cols)\n",
    "\n",
    "dtypes = {'id':str,'name':str,'records':int,'date':int,'time':int,\n",
    "          'record_id':str,'system_status':str,'latitude':float,'lat_hem':str,\n",
    "          'longitude':float,'lon_hem':str,'max_windspeed':int,'min_pressure':int,\n",
    "          'radii_34kt_ne':int,'radii_34kt_se':int,'radii_34kt_sw':int,'radii_34kt_nw':int,\n",
    "          'radii_50kt_ne':int,'radii_50kt_se':int,'radii_50kt_sw':int,'radii_50kt_nw':int,\n",
    "          'radii_64kt_ne':int,'radii_64kt_se':int,'radii_64kt_sw':int,'radii_64kt_nw':int}\n",
    "\n",
    "df_data = df_data.astype(dtypes)\n",
    "\n",
    "# strip leading spaces\n",
    "df_data['name']=df_data['name'].str.strip()\n",
    "\n",
    "# set negative longitudes for western hemisphere\n",
    "df_data['longitude']=-df_data['longitude']\n",
    "\n",
    "# write the dataframe out to csv\n",
    "formatted_fn = 'source_data/formatted_hurdat_data.csv'\n",
    "df_data.to_csv(formatted_fn,index=False)\n",
    "\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data for Hurricane HARVEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.read_csv('source_data/formatted_hurdat_data.csv')\n",
    "\n",
    "df_data[df_data['id']=='AL092017'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model area grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get events which make happened since 2000\n",
    "df_data_in_period = df_data[df_data['date']>=20000101]\n",
    "\n",
    "df_data_in_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data\n",
    "df_events = df_data_in_period['id'].drop_duplicates().reset_index()[['id']]\n",
    "df_events['event_id']=df_events.index+1\n",
    "\n",
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the event ids into the data dataframe\n",
    "df_data_in_period = df_data_in_period.merge(df_events,on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grid = pd.read_csv('source_data/us_grid.csv')\n",
    "\n",
    "df_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show grid\n",
    "geometry = [Point(xy) for xy in zip(df_grid['longitude'], df_grid['latitude'])]\n",
    "gdf = GeoDataFrame(df_grid, geometry=geometry)   \n",
    "\n",
    "#this is a simple map that comes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "gdf.plot(ax=world.plot(figsize=(20, 12)), marker='o', color='red', markersize=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cartisian indicies\n",
    "df_x = df_grid[['latitude']].drop_duplicates().reset_index()[['latitude']]\n",
    "df_x['x_index']=df_x.index+1\n",
    "\n",
    "df_y = df_grid[['longitude']].drop_duplicates().reset_index()[['longitude']]\n",
    "df_y['y_index']=df_y.index+1\n",
    "\n",
    "df_grid_coord = df_grid.merge(df_x,on='latitude').merge(df_y,on='longitude')\n",
    "\n",
    "# create area peril id for grid\n",
    "df_grid_coord['areaperil_id']=df_grid_coord.index+1\n",
    "\n",
    "del df_grid_coord['geometry']\n",
    "\n",
    "df_grid_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find areaperil cell of track point\n",
    "df_events_ap = df_data_in_period.merge(df_grid_coord,on=['latitude','longitude'])\n",
    "\n",
    "df_events_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove records below windspeed threhold\n",
    "v_thresh = 45\n",
    "df_events_thresh = df_events_ap[df_events_ap['max_windspeed'] >= v_thresh]\n",
    "\n",
    "df_events_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_thresh[['id','name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index windspeeds and assign size\n",
    "df_intensity = df_events_thresh['max_windspeed'].drop_duplicates().sort_values().reset_index()\n",
    "df_intensity['intensity_bin_index']=df_intensity.index+1\n",
    "\n",
    "df_intensity = df_intensity[['intensity_bin_index','max_windspeed']]\n",
    "\n",
    "df_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_intensity = df_events_thresh.merge(df_intensity,on='max_windspeed').sort_values(by=['date','time'])\n",
    "df_events_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_intensity = df_events_thresh.merge(df_intensity,on='max_windspeed').sort_values(by=['date','time'])\n",
    "\n",
    "# generate intensity values per event & areaperil\n",
    "\n",
    "\n",
    "lst_fp = []\n",
    "\n",
    "for index, row in df_events_intensity.iterrows():\n",
    "    #print(row[['areaperil_id','x_index','y_index','intensity_bin_index','event_id']])\n",
    "    i=0\n",
    "    event_id = row['event_id']\n",
    "    areaperil_id = row['areaperil_id']\n",
    "    intensity_bin = row['intensity_bin_index']\n",
    "        \n",
    "    row_fp = [event_id,areaperil_id,intensity_bin]\n",
    "    lst_fp.append(row_fp)\n",
    "    \n",
    "    #### to do - add in radius ####\n",
    "    \n",
    "    #if radius > 1:\n",
    "    #    for r in range(radius):\n",
    "    #        \n",
    "    #    \n",
    "    #for i in range(radius):\n",
    "    #    i+=1\n",
    "    #    print(event_id, radius, i)\n",
    "    \n",
    "df_footprint = pd.DataFrame(data=lst_fp,columns=['event_id','area_peril_id','intensity_bin_index'],dtype='int')\n",
    "df_footprint['probability']=1\n",
    "\n",
    "df_footprint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model files out\n",
    "df_events[['event_id','id']].to_csv('model_data/events.csv',index=False)\n",
    "df_footprint.to_csv('model_data/footprint.csv',index=False)\n",
    "df_intensity.to_csv('model_data/intensity_bin_dict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write keys data out\n",
    "df_grid_coord[['area_peril_id','latitude','longitude']].to_csv('keys_data/areaperil_dict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events['key']=1\n",
    "df_grid['key']=1\n",
    "\n",
    "lon_lat_tollerance = 1\n",
    "\n",
    "e_id = 'AL092017'\n",
    "\n",
    "min_lat = df_events[df_events['id']==e_id]['latitude'].min() - lon_lat_tollerance\n",
    "max_lat = df_events[df_events['id']==e_id]['latitude'].max() + lon_lat_tollerance\n",
    "min_lon = df_events[df_events['id']==e_id]['longitude'].min() - lon_lat_tollerance\n",
    "max_lon = df_events[df_events['id']==e_id]['longitude'].max() + lon_lat_tollerance\n",
    "\n",
    "print(min_lat,max_lat,min_lon,max_lon)\n",
    "\n",
    "df_grid_e = df_grid[\n",
    "    (df_grid['grid_latitude']>=min_lat) &\n",
    "    (df_grid['grid_latitude']<=max_lat) &\n",
    "    (df_grid['grid_longitude']<=-min_lon) &\n",
    "    (df_grid['grid_longitude']>=-max_lon)\n",
    "]\n",
    "\n",
    "\n",
    "df_e = df_events[df_events['id']==e_id].merge(df_grid_e)\n",
    "\n",
    "\n",
    "\n",
    "#df_e[['latitude','longitude','grid_latitude','grid_longitude']] \n",
    "\n",
    "df_e['distance'] = df_e.apply(lambda x: get_distance(\n",
    "    x['latitude'],\n",
    "    x['longitude'],\n",
    "    x['grid_latitude'],\n",
    "    x['grid_longitude']),axis=1)\n",
    "\n",
    "df_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e.sort_values(by='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distance(44.95,-67.25,44.95,-67.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events['radii_34kt_nw'].astype('float').max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[df_events['radii_34kt_nw'].str.strip()=='600']\n",
    "df_data[df_data['id'].str.strip()=='AL012016'].head(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events[['id','name']].drop_duplicates().tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to calculate distance between two lat-lon points\n",
    "\n",
    "def get_distance(lat1,lon1,lat2,lon2):\n",
    "    lat1_r = radians(abs(lat1))\n",
    "    lon1_r = radians(abs(lon1))\n",
    "    lat2_r = radians(abs(lat2))\n",
    "    lon2_r = radians(abs(lon2))\n",
    "\n",
    "    dlon = lon2_r - lon1_r\n",
    "    dlat = lat2_r - lat1_r\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1_r) * cos(lat2_r) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = earth_radius * c\n",
    "\n",
    "    return distance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
